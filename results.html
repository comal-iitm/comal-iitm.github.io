
<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>CoMaL</title>
<link href="styles/main.css" rel="stylesheet" type="text/css">
<!--[if lte IE 8]>
<script type="text/javascript" src="js/html5shiv.js"></script>
<![endif]-->
</head>

<body>
<div id="wrapper">
  <header id="top">
    <h1>CoMaL - CoMaL: Good Features to Match on Object Boundaries</h1>
<h2><a href=" 	http://www.cs.duke.edu/~swarnakr">Swarna K Ravindran</a> and <a href="http://www.cse.iitm.ac.in/~amittal/"> Anurag Mittal</a> </h2>
<h2> Indian Institute of Technology Madras</h2>   

   
  <figure><img src="docs/images/title.png" width="100%"  alt="" /></a></figure>  
 
<p>
&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
<a href="docs/cvpr16_CoMaL.pdf" target="_blank">CVPR 2016 PDF</a> &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
<a href="docs/CoMaL_code.zip" target="_blank">CODE</a>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
 <a href="docs/additional_results.zip",style="text-align:center">Additional Results</a>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;
<b><font color="#000066">Download CoMaL dataset</font></b>
 <a href="docs/CoMaL_Dataset1.zip",style="text-align:right">[1]</a>
 <a href="docs/CoMaL_Dataset2.zip",style="text-align:right">[2]</a>
 <a href="docs/CoMaL_Dataset3.zip",style="text-align:right">[3]</a></p>

  <br>
  <br>
  
    <h2>Abstract</h2>
    
    <p></p>
    
    <p>Traditional Feature Detectors and Trackers use information aggregation in 2D patches to detect and match discriminative patches.  However, this information does not remain the same at object boundaries when there is object motion against a significantly varying background.  In this paper, we propose a new approach for feature detection, tracking and re-detection that gives significantly improved results at the object boundaries.  We utilize <i>level lines</i> or <i>iso-intensity curves</i> that often remain stable and can be reliably 
detected even at the object boundaries, which they often trace.
Stable portions of long level lines are detected and points of high curvature  are detected on such curves for corner detection.   
Further, this level line  
is used to separate the portions belonging to the two objects, which is then used for robust matching of such points.  While such CoMaL (Corners on 
Maximally-stable Level Line Segments) points were found to be much more reliable at the object boundary
regions, they perform 
comparably at the interior regions as well. This is illustrated in exhaustive experiments 
on real-world datasets.
 </p>
<br><br>
  
  <nav id="mainnav">
      <ul>
        <li><a href="index.html" >Motivation</a></li>
        <li><a href="method.html">Method</a></li>
        <li><a href="results.html" class="thispage">Results</a></li>
        <li><a href="future.html">CoMaL Tracking</a></li>

      </ul>
    </nav>
  
    </header>

<article id="results">
<p>
Results are shown on the KITTI tracking dataset (Figure 10), CoMaL dataset (Figure 11), KITTI Stereo dataset (Figure 12), KITTI Flow dataset (Figure 13) and Oxford dataset (Figure 14).
</p>

<div align="center">
<table width=660 border="0">
        <tr> <td><div align="center"><img src="docs/images/comic1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/comic2.png" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/hesssift1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/hesssift2.png" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/fassol1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/fassol2.png" width="290px"  /></div></td>
	</tr>
</table>
</div>

	<div text-align="center", style="margin-top:6pt""><strong>Figure 10.</strong> Frame numbers 88 and 93 in the sequence Car-B from the KITTI dataset [4] showing CoMaL + SSD matches in the first row
followed by next performing combination: Hessian [5] + SIFT [6] and FAST [7] + NSD [8] in the 2nd and 3rd rows respectively.
CoMaL points are matched more numerously and accurately at the object boundary regions in spite of a significant change in the background.
</div>

<br><br>
 
<div align="center">
<table width=660 border="0">
        <tr> <td><div align="center"><img src="docs/images/boxcomic1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/boxcomic2.png" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/boxhes1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/boxhes2.png" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/hero_comic1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/hero_comic2.png" width="290px"  /></div></td>
	</tr>
<tr> <td><div align="center"><img src="docs/images/hero_hes1.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/hero_hes2.png" width="290px"  /></div></td>
	</tr>
</table>
</div>

	<div text-align="center", style="margin-top:6pt""><strong>Figure 11.</strong> First two rows: matches on a Homogenous object - Box.  Bottom two rows: Matches on a Textured Object -  Hero.  
CoMaL + SSD matches are shown in the first row images while Hessian + SIFT matches are shown in the second row images.
</div>


<div align="center">
<table width=660 border="0">
        <tr> <td><div align="center"><img src="docs/images/im553_harronmser_ssd_2.jpg" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/im554_harronmser_ssd_2.jpg" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/im553_hes_sift_2.jpg" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/im554_hes_sift_2.jpg" width="290px"  /></div></td>
	</tr>
</table>
</div>

	<div text-align="center", style="margin-top:6pt""><strong>Figure 12.</strong> Matches on image stereo pair 138 from the KITTI dataset. CoMaL + SSD matches are shown in the first row 
while Hessian + SIFT matches are shown in the second. CoMaL matches are clearly more numerous.
</div>



<div align="center">
<table width=660 border="0">
        <tr> <td><div align="center"><img src="docs/images/im253_harronmser_ssd_2.jpg" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/im255_harronmser_ssd_2.jpg" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/im253_hes_sift_2.jpg" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/im255_hes_sift_2.jpg" width="290px"  /></div></td>
	</tr>
</table>
</div>

	<div text-align="center", style="margin-top:6pt""><strong>Figure 13.</strong> Matches on image flow pair 63 from the KITTI dataset. CoMaL + SSD matches are shown in the first row 
while Hessian + SIFT matches are shown in the second.
</div>


<div align="center">
<table width=660 border="0">
        <tr> <td><div align="center"><img src="docs/images/RepBike3.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/CorresBike3.png" width="290px"  /></div></td>
	</tr>
        <tr> <td><div align="center"><img src="docs/images/RepLuvn3.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/CorresLuvn3.png" width="290px"  /></div></td>
	</tr>

        <tr> <td><div align="center"><img src="docs/images/RepUbc3.png" width="290px"/></div></td>
		<td><div align="center"><img src="docs/images/CorresUbc3.png" width="290px"  /></div></td>
	</tr>

</table>
</div>

	<div text-align="center", style="margin-top:6pt""><strong>Figure 14.</strong> Repeatability and Correspondences Graphs for the Bikes, Leuven and UBC sequences from the Oxford dataset in the first, second and third rows respectively.
</div>

<br><br><br><br>

</article>
<div>
    <h2>References</h2>
[1] G. Zhang, and Z. Dong, J. Jia  et al. Efficient non-consecutive feature tracking for structure-from-motion. In ECCV 2010.
 <br><br>
[2] J. Matas, O. Chum, M. Urban, and T. Pajdla. Robust wide baseline stereo from maximally stable extremal regions.
In BMVC, 2002.
<br><br>
[3] C. Harris and M. Stephens. A combined corner and edge detector. In Alvey vision conference, 1988.
<br><br>
[4] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun. Vision meets robotics: The KITTI dataset. In The International Journal of Robotics Research, 2013.
<br><br>
[5] K. Mikolajczyk and C. Schmid. Scale & affine invariant interest point detectors. In IJCV, 2004.
  <br><br>
[6] D. Lowe. Distinctive Image Features from Scale-Invariant Keypoints. In IJCV 2004.
<br><br>
[7] E. Rosten and T. Drummond. Machine learning for high-speed corner detection. In ECCV 2006.
<br><br>
[8] J. Byrne and J. Shi. Nested shape descriptors. In ICCV 2013.

<br><br>

[9] B. Lucas, T Kanade et al. An iterative image registration technique with an application to stereo vision. In IJCAI 1981.

</div>

<br><br><br><br><br><br>
<footer>
    <p> Contact: swarnakr@cs.duke.edu, amittal@cse.iitm.ac.in </p>
  </footer>
</div>
</body>
</html>

